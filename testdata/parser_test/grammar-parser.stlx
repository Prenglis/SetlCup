// The parser implemented in the function parseExpr parses an arithmetic 
// expression according to the following EBNF grammar.
// 
// grammar : rule+ 
//         ;
// 
// rule : VAR ':' body ('|' body )* ';' 
//      ;
//  
// body : item*
//      ; 
// 
// item : VAR     
//      | TOKEN   
//      | LITERAL 
//      ;

// Read a grammar from the file f, parse the grammar, and return it.
readGrammar := procedure(f) {
    gs := join(readFile(f), "\n");
    tl := tokenizeString(gs);
    return parseGrammar(tl);
};

// This procedure takes a token list tl and tries to interpret this list
// as an arithmetic expression.
parseGrammar := procedure(tl) {
    [rule, rl] := parseRule(tl);
    ruleList := [ rule ];
    while (#rl >= 1) {
        [rule, rl] := parseRule(rl);
        ruleList += [ rule ];
    }
    return collectSimpleRules(ruleList);
};

collectSimpleRules := procedure(ruleList) {
    rules     := [];
    variables := {};
    for ([v, bodyList] in ruleList) {
        variables += { v };
        for (body in bodyList) {
            rules += [ [v, body] ];
        }
    }
    start := rules[1][1];
    return [rules, variables, start];
};

parseRule := procedure(tl) {
    [head, rl] := [args(tl[1])[1], tl[2..]];
    assert(fct(tl[1]) == "Var", "parseRule($tl$)");
    assert(rl[1] == ":", "parseRule($tl$)");
    [body, rl] := parseBody(rl[2..]);
    bodyList := [ body ];
    while (#rl >= 1 && rl[1] == "|") {
        [body, rl] := parseBody(rl[2..]);
        bodyList += [ body ];
    }
    assert(rl[1] == ";", "parseRule($tl$), rl = $rl$");
    return [ [head, bodyList], rl[2..]];
};

parseBody := procedure(tl) {
    itemList := [];
    while (#tl >= 1 && !(tl[1] in [ "|", ";" ])) {
        [item, tl] := parseItem(tl);
        itemList += [ item ];
    }
    return [itemList, tl];
};

parseItem := procedure(tl) {
    match (tl) {
        case [ Var(v  ) | rl] : return [ Var(v),     rl];
        case [ Token(t) | rl] : return [ Token(t),   rl];
        default : abort("parse error in parseItem($tl$)");
    }
};

// This procedure partitions the string s into a list of tokens.
// It recognizes numbers, the operator symbols "+", "-", "*", "/", "**"
// and the parentheses "(" and ")".
tokenizeString := procedure(s) {
    tokenList := [];
    scan (s) {
        regex '[:|;]'              as [ o ]: tokenList += [ o        ];
        regex '[a-z][a-zA-Z_0-9]*' as [ v ]: tokenList += [ Var(v)   ];
        regex '[A-Z][A-Z_0-9]*'    as [ t ]: tokenList += [ Token(t) ];
        regex '''[^'']*'''         as [ l ]: tokenList += [ Token(l) ];
        regex '[ \t\v\n\r]+'               : // skip
        regex '.|\n'               as [ c ]: abort("tokenizeString: $c$");
    }
    return tokenList;
};

grammar2String := procedure(ruleList) {
    result := "";
    for ([v, bl] in ruleList) {
        bh := bl[1]; br := bl[2..];
        result += v + ":\n      " + itemList2String(bh) + "\n";
        result += bodyList2String(br);
    }
    return result;
};

bodyList2String := procedure(l) {    
    match (l) {
        case []: 
             return "    ;\n\n";
        case [bh| bl]: 
             return "    | " + itemList2String(bh) + "\n" + bodyList2String(bl);
    }
};

itemList2String := procedure(l) {
    match (l) {
        case []: 
             return "";
        case [x]: 
             return item2String(x);
        case [h | t]: 
             return item2String(h) + " " + itemList2String(t);
    }
};

item2String := procedure(i) {
    match (i) {
        case Var(v):   return v;
        case Token(t): return t;
        default:       abort("item2String($i$)");
    }
};

testParser := procedure(f) {
    for ([v, il] in readGrammar(f)[1]) {
         print("$v$ -> $itemList2String(il)$");
    }
};

// testParser("expr.g");
